{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Финальный проект\n",
    "\n",
    "Работу выполнила Камская Милена БКЛ-211"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные функции бота:\n",
    "1. Генерация текста на цепях Маркова\n",
    "2. Поиск наиболее подходящего ответа из базы данных\n",
    "3. Поиграться с моделями(найти максимально похожее слово, выбросить лишнее из строки), обученной на выкачаных и обработаных текстах"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все нужные импорты для первой части будут здесь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Имя\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from string import punctuation\n",
    "import re\n",
    "import pymorphy2\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала собрем все книги, на основе которых мы будем обучать модель. В списке lst лежат ссылки на 30 рандомных книг, написанных в жанре фантастика русскими авторами. С помощью BeautifulSoup мы выкачиваем текст со всех страниц и складываем его в один большой файл формата .txt, с которым и будем работать в дальнейшем. Вышло примерно 130к строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def get_text(url):\n",
    "    rs = requests.get(url).text\n",
    "    text = re.sub(r'\\<[^>]*\\>', '', rs)\n",
    "\n",
    "    return text\n",
    "\n",
    "with open('sbornik.txt', 'a', encoding='UTF-8') as output:\n",
    "    lst = ['http://lib.ru/RUFANT/ABRANOW/horsmen1.txt', 'http://lib.ru/RUFANT/ABRANOW/horsmen2.txt', 'http://lib.ru/RUFANT/ABRANOW/horsmen3.txt', \n",
    "           'http://lib.ru/RUFANT/ABRANOW/selesta.txt', 'http://lib.ru/RUFANT/ABRANOW/aladdine.txt', 'http://lib.ru/RUFANT/ABRANOW/goodnght.txt', \n",
    "           'http://lib.ru/RUFANT/ABRANOW/guest.txt', 'http://lib.ru/RUFANT/ABRANOW/imprshad.txt', 'http://lib.ru/RUFANT/ABRANOW/permit.txt', \n",
    "           'http://lib.ru/RUFANT/ABRANOW/prince.txt', 'http://lib.ru/RUFANT/ABRANOW/timescal.txt', 'http://lib.ru/RUFANT/ABRANOW/walking.txt', \n",
    "           'http://lib.ru/RUFANT/ABRANOW/r_bal.txt', 'http://lib.ru/RUFANT/ANDERSEN/deti.txt', 'http://lib.ru/RUFANT/ANDERSEN/deti2.txt', \n",
    "           'http://lib.ru/RUFANT/ANDERSEN/deti3.txt', 'http://lib.ru/RUFANT/ANDERSEN/deti4.txt', 'http://lib.ru/RUFANT/ANDERSEN/deti5.txt', \n",
    "           'http://lib.ru/NEWPROZA/WULF/asylum.txt', 'http://lib.ru/NEWPROZA/WULF/zion.txt', 'http://lib.ru/NEWPROZA/WULF/erez2.txt', \n",
    "           'http://lib.ru/NEWPROZA/WULF/vodolazia.txt', 'http://lib.ru/RUFANT/LAPIN/children.txt', 'http://lib.ru/RUFANT/LAPIN/day_13.txt',\n",
    "           'http://lib.ru/RUFANT/LAPIN/magger.txt', 'http://lib.ru/KLYUCHWSKIJ/cwetok.txt', 'http://lib.ru/RUFANT/SAMSONOV/korabl.txt', \n",
    "           'http://lib.ru/RUFANT/SAMSONOV/imperia.txt', 'http://lib.ru/RUFANT/SAMSONOV/maxim.txt', 'http://lib.ru/RUFANT/SAMSONOV/r_glagol.txt']\n",
    "    for item in lst:\n",
    "        text = get_text(item)\n",
    "        print(text + '\\n', file=output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Займемся подготовкой текста для обучения модели!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_ru(file_text):\n",
    "    # firstly let's apply nltk tokenization\n",
    "    tokens = word_tokenize(file_text)\n",
    "\n",
    "    # let's delete punctuation symbols\n",
    "    tokens = [i for i in tokens if (i not in string.punctuation)]\n",
    "\n",
    "    # deleting stop_words\n",
    "    stop_words = stopwords.words('russian')\n",
    "    stop_words.extend(['что', 'это', 'так', 'вот', 'быть', 'как', 'в', '—', '–', 'к', 'на', '...'])\n",
    "    tokens = [i for i in tokens if (i not in stop_words)]\n",
    "\n",
    "    # cleaning words\n",
    "    tokens = [i.replace(\"«\", \"\").replace(\"»\", \"\") for i in tokens]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbornik = open('sbornik.txt', 'r', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [tokenize_ru(sent) for sent in sent_tokenize(sbornik, 'russian')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199855\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем морфологический парсинг!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def lemmatize(text):\n",
    "    res = list()\n",
    "    for item in text:\n",
    "        p = morph.parse(item)[0]\n",
    "        res.append(p.normal_form)\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sbornik.txt', 'w', encoding='UTF-8') as output:\n",
    "    for sent in sentences:\n",
    "        lem = lemmatize(sent)\n",
    "        lem_sentence = ' '.join(lem)\n",
    "        print(lem_sentence, file=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "s = open('sbornik.txt', 'r', encoding='UTF-8').read()\n",
    "s_del = ''.join(c for c in s if c not in string.ascii_letters)\n",
    "s_r = s_del.replace('-', '')\n",
    "with open('sbornik.txt', 'w', encoding='UTF-8') as output:\n",
    "    print(s_r, file=output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поздравляю, мы подготовили тексты к следующему этапу!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Приступаем к обучению модели!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import logging\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'sbornik.txt'\n",
    "data = gensim.models.word2vec.LineSentence(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(data, vector_size=300, window=5, min_count=2, epochs=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь я обучила модель, теперь посмотрим сколько слов в словаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32586\n"
     ]
    }
   ],
   "source": [
    "print(len(model.wv.key_to_index))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее я проверяю работу функций. Все стандартно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('папа', 0.4027484357357025),\n",
       " ('таня', 0.36235761642456055),\n",
       " ('феликс', 0.35526520013809204),\n",
       " ('танечка', 0.3332690894603729),\n",
       " ('тамара', 0.3192366361618042),\n",
       " ('подруга', 0.31833958625793457),\n",
       " ('минни', 0.31569305062294006),\n",
       " ('коля', 0.3117457330226898),\n",
       " ('дядя', 0.3073084056377411),\n",
       " ('барышня', 0.3023766279220581)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_similar_one(word):\n",
    "    return model.wv.most_similar(str(word).lower(), topn=10)\n",
    "\n",
    "most_similar_one('Мама')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('банкир', 0.21765203773975372),\n",
       " ('целый', 0.20187951624393463),\n",
       " ('строго', 0.20174622535705566),\n",
       " ('шура', 0.19786711037158966),\n",
       " ('блёкло', 0.19669906795024872),\n",
       " ('затормозить', 0.19427995383739471),\n",
       " ('пустовать', 0.1918061524629593),\n",
       " ('педантично', 0.19146472215652466),\n",
       " ('чум', 0.1912911832332611),\n",
       " ('поролоновомебельный', 0.19083306193351746)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_similar_two(word):\n",
    "    return model.wv.most_similar(positive=str(word.split()[0]).lower(), negative=str(word.split()[1]).lower(), topn=10)\n",
    "\n",
    "most_similar_two('хороший плохой')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'дочь'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def doesnt_match(line):\n",
    "    return model.wv.doesnt_match(line.lower().split())\n",
    "\n",
    "doesnt_match('Родитель семья сын дочь')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбираемся с поиском ответов по базе!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я нашла какую-то базу, которую предлагали на олимпиаде по машинному обучению. В ней лежат ответы на вопросы с пометкой good/bad/neutral. Я заранее почистила ее от плохих слов, чтобы бот оставался на добром, но, простите, ничего не обещаю... просто выключайте его, переходите к другим функциям - не терпите. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_2</th>\n",
       "      <th>context_1</th>\n",
       "      <th>context_0</th>\n",
       "      <th>reply</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19639</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>если ты не хочешь , чтобы она знала , я не ска...</td>\n",
       "      <td>елена ?</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18302</th>\n",
       "      <td>теперь ты в безопасности .</td>\n",
       "      <td>никому не нужно знать , что ты здесь .</td>\n",
       "      <td>где мой дядя ?</td>\n",
       "      <td>он мертв .</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>о , да , я могу остаться .</td>\n",
       "      <td>давай</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        context_2                               context_1  \\\n",
       "19639                         NaN                                     NaN   \n",
       "18302  теперь ты в безопасности .  никому не нужно знать , что ты здесь .   \n",
       "2150                          NaN                                     NaN   \n",
       "\n",
       "                                               context_0       reply    label  \n",
       "19639  если ты не хочешь , чтобы она знала , я не ска...     елена ?     good  \n",
       "18302                                     где мой дядя ?  он мертв .     good  \n",
       "2150                          о , да , я могу остаться .       давай  neutral  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "good = pd.read_csv('good.tsv', sep='\\t', on_bad_lines='skip')\n",
    "good.sample(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Превращаем тексты в числовые векторы, чтобы осуществлять по ним приближённый поиск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59977, 14115)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "vectorizer.fit(good.context_0)\n",
    "matrix_big = vectorizer.transform(good.context_0)\n",
    "print(matrix_big.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сокращаем размерность матрицы. Алгоритм PCA (метод главных компонент) подбирает матрицу проекции так, чтобы исходную матрицу можно было потом восстановить с наименьшей среднеквадратической ошибкой."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы представляем каждый текст не 14123-мерным, а всего лишь 300-мерным вектором"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59977, 300)\n",
      "0.43971940059690495\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=300)\n",
    "svd.fit(matrix_big)\n",
    "matrix_small = svd.transform(matrix_big)\n",
    "\n",
    "print(matrix_small.shape)\n",
    "print(svd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пишем класс для случайного выбора из всех подходящих ответов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import BallTree\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "def softmax(x):\n",
    "    proba = np.exp(-x)\n",
    "    return proba / sum(proba)\n",
    "\n",
    "class NeighborSampler(BaseEstimator):\n",
    "    def init__(self, k=5, temperature=1.0):\n",
    "        self.k = k\n",
    "        self.temperature = temperature\n",
    "    def fit(self, X, y):\n",
    "        self.tree = BallTree(X)\n",
    "        self.y_ = np.array(y)\n",
    "    def predict(self, X, random_state=None):\n",
    "        distances, indices = self.tree.query(X, return_distance=True)\n",
    "        result = []\n",
    "        for distance, index in zip(distances, indices):\n",
    "            result.append(np.random.choice(index, p=softmax(distance)))\n",
    "        return self.y_[result]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все соединяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "ns = NeighborSampler()\n",
    "ns.fit(matrix_small, good.reply)\n",
    "pipe = make_pipeline(vectorizer, svd, ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'хорошо . а у вас ?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def talk(text):\n",
    "    return str(pipe.predict([str(text)]))[2:-2]\n",
    "\n",
    "talk('как дела?')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация на цепях Маркова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут уже не так весело, но это достаточно простая и милая генерация, основанная на текстах, которые я выкачала. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цепь Маркова — это последовательность событий, где каждое новое событие зависит только от предыдущего. Например, после одного слова может стоять другое слово. Для нашей работы алгоритму всегда нужен исходный текст (он же корпус) — глядя на этот текст, алгоритм поймёт, какие слова обычно идут друг за другом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "text = open('sbornik_old.txt', encoding='utf8').read()\n",
    "corpus = text.split()\n",
    "\n",
    "def make_pairs(corpus):\n",
    "    # перебираем все слова в корпусе, кроме последнего\n",
    "    for i in range(len(corpus)-1):\n",
    "        # генерируем новую пару и возвращаем её как результат работы функции\n",
    "        yield (corpus[i], corpus[i+1])\n",
    "\n",
    "def markov(www):        \n",
    "    pairs = make_pairs(corpus)\n",
    "    word_dict = {}\n",
    "    for word_1, word_2 in pairs:\n",
    "        if word_1 in word_dict.keys():\n",
    "            word_dict[word_1].append(word_2)\n",
    "        else:\n",
    "            word_dict[word_1] = [word_2]\n",
    "    first_word = www\n",
    "    while first_word.islower():\n",
    "        first_word = np.random.choice(corpus)\n",
    "    chain = [first_word]\n",
    "    n_words = 10\n",
    "    for i in range(n_words):\n",
    "        chain.append(np.random.choice(word_dict[chain[-1]]))\n",
    "    return ' '.join(chain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TelegramBot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну тут все для бота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyTelegramBotAPI in c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyTelegramBotAPI) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->pyTelegramBotAPI) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->pyTelegramBotAPI) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->pyTelegramBotAPI) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->pyTelegramBotAPI) (2021.10.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install pyTelegramBotAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-telegram-bot[socks] in c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (20.1)\n",
      "Requirement already satisfied: httpx[http2]~=0.23.3 in c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-telegram-bot[socks]) (0.23.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx[http2]~=0.23.3->python-telegram-bot[socks]) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx[http2]~=0.23.3->python-telegram-bot[socks]) (2021.10.8)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx[http2]~=0.23.3->python-telegram-bot[socks]) (1.5.0)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx[http2]~=0.23.3->python-telegram-bot[socks]) (0.16.3)\n",
      "Requirement already satisfied: h2<5,>=3 in c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx[http2]~=0.23.3->python-telegram-bot[socks]) (4.1.0)\n",
      "Requirement already satisfied: socksio==1.* in c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx[http2]~=0.23.3->python-telegram-bot[socks]) (1.0.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from h2<5,>=3->httpx[http2]~=0.23.3->python-telegram-bot[socks]) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from h2<5,>=3->httpx[http2]~=0.23.3->python-telegram-bot[socks]) (4.0.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore<0.17.0,>=0.15.0->httpx[http2]~=0.23.3->python-telegram-bot[socks]) (3.6.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore<0.17.0,>=0.15.0->httpx[http2]~=0.23.3->python-telegram-bot[socks]) (0.14.0)\n",
      "Requirement already satisfied: idna in c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rfc3986[idna2008]<2,>=1.3->httpx[http2]~=0.23.3->python-telegram-bot[socks]) (3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\имя\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install python-telegram-bot[socks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telebot  # импортируем модуль pyTelegramBotAPI\n",
    "import conf     # импортируем наш секретный токен\n",
    "from telebot import types\n",
    "\n",
    "bot = telebot.TeleBot(conf.TOKEN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее прописываю реакцию на комманды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(commands=['start'])\n",
    "def start(message):\n",
    "    markup = types.ReplyKeyboardMarkup(resize_keyboard=True)\n",
    "    btn1 = types.KeyboardButton(\"Расскажи, что ты умеешь\")\n",
    "    btn2 = types.KeyboardButton(\"Хочу побаловаться с моделью!\")\n",
    "    btn3 = types.KeyboardButton(\"Плевать, давай генерировать!\")\n",
    "    markup.add(btn1, btn2, btn3)\n",
    "    bot.send_message(message.chat.id, 'Здравствуйте!', reply_markup=markup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(commands=['help'])\n",
    "def help(message):\n",
    "    helpani = '''Что я умею?\n",
    "\n",
    "• Генерировать текст при помощи цепей Маркова\n",
    "• Общаться с тобой, используя ответы из базы данных\n",
    "• Выводить некоторые прикольчики из моделей - попробуй и узнаешь!'''\n",
    "    bot.send_message(message.chat.id, helpani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(commands=['bye'])\n",
    "def finish(message):\n",
    "    bot.send_message(message.chat.id, 'До скорых встреч! Целую, обнимаю)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы обнаружили нечто"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(commands=['special'])\n",
    "def wow(message):\n",
    "    bot.send_message(message.chat.id, 'Поздравляю, ты нашел пасхалку!')\n",
    "    photo = open(\"пасхалка/\" + 'халло.jpg', \"rb\")\n",
    "    bot.send_photo(message.chat.id, photo, 'Так и я делала этот проект, всем спасибо за внимание!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь прописываю его реакцию на текстовые сообщения от пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(content_types=['text'])\n",
    "def func(message: types.Message):\n",
    "    if message.text == \"Расскажи, что ты умеешь\":\n",
    "        helpani = '''Что я умею?\n",
    "\n",
    "                    • Генерировать текст при помощи цепей Маркова\n",
    "                    • Общаться с тобой, используя ответы из базы данных\n",
    "                    • Выводить некоторые прикольчики из моделей - попробуй и узнаешь!'''\n",
    "        bot.send_message(message.chat.id, helpani)\n",
    "        markup = types.ReplyKeyboardMarkup(resize_keyboard=True)\n",
    "        button1 = types.KeyboardButton(\"Вернемся в главное меню!\")\n",
    "        markup.add(button1)\n",
    "        bot.send_message(message.chat.id, \n",
    "                         text=\"Ну чего, возвращаемся в главное меню?\", \n",
    "                         reply_markup=markup)\n",
    "        \n",
    "    elif message.text == \"Вернемся в главное меню!\":\n",
    "        markup = types.ReplyKeyboardMarkup(resize_keyboard=True)\n",
    "        btn1 = types.KeyboardButton(\"Расскажи, что ты умеешь\")\n",
    "        btn2 = types.KeyboardButton(\"Хочу побаловаться с моделью!\")\n",
    "        btn3 = types.KeyboardButton(\"Плевать, давай генерировать!\")\n",
    "        markup.add(btn1, btn2, btn3)\n",
    "        bot.send_message(message.chat.id,\n",
    "                         text=\"С возвращением, друг!\",\n",
    "                         reply_markup=markup)\n",
    "\n",
    "    elif message.text == \"Хочу побаловаться с моделью!\":\n",
    "        markup = types.ReplyKeyboardMarkup(resize_keyboard=True)\n",
    "        m_sim = types.KeyboardButton(\"Хочу найти ближайшее слово к моему слову!\")\n",
    "        a_sim = types.KeyboardButton(\"Хочу найти ассоциацию к словам!\")\n",
    "        d_match = types.KeyboardButton(\"Хочу найти лишнее слово в строке\")\n",
    "        b = types.KeyboardButton(\"Вернемся в главное меню!\")\n",
    "        markup.add(m_sim, a_sim, d_match)\n",
    "        markup.row(b)\n",
    "        bot.send_message(message.chat.id,\n",
    "                         text=\"Выбери действие, друг!\",\n",
    "                         reply_markup=markup)\n",
    "        \n",
    "    elif message.text == \"Хочу найти ближайшее слово к моему слову!\":\n",
    "        bot.send_message(message.chat.id, text=\"Отправь мне слово\") \n",
    "        bot.register_next_step_handler(message, msimilar_one)\n",
    "    \n",
    "    elif message.text == \"Хочу найти ассоциацию к словам!\":\n",
    "        bot.send_message(message.chat.id, text=\"Отправь мне ровно 2 слова с разными оттенками значения(сначала positive, затем negаtive) через пробел\") \n",
    "        bot.register_next_step_handler(message, msimilar_two)\n",
    "\n",
    "    elif message.text == \"Хочу найти лишнее слово в строке\":\n",
    "        bot.send_message(message.chat.id, text=\"Отправь мне четыре слова через пробел\") \n",
    "        bot.register_next_step_handler(message, match_line)\n",
    "\n",
    "    elif message.text == \"Плевать, давай генерировать!\":\n",
    "        markup = types.ReplyKeyboardMarkup(resize_keyboard=True)\n",
    "        first_option = types.KeyboardButton(\"Сгенерируй мне что-то, в чем я буду вечно искать смысл\")\n",
    "        second_option = types.KeyboardButton(\"А болтать ты умеешь?\")\n",
    "        b = types.KeyboardButton(\"Вернемся в главное меню!\")\n",
    "        markup.add(first_option, second_option)\n",
    "        markup.row(b)\n",
    "        bot.send_message(message.chat.id,\n",
    "                         text=\"Выбери действие, друг!\",\n",
    "                         reply_markup=markup)\n",
    "    \n",
    "    elif message.text == \"Сгенерируй мне что-то, в чем я буду вечно искать смысл\":\n",
    "        bot.send_message(message.chat.id, text=\"Отправь мне слово\") \n",
    "        bot.register_next_step_handler(message, gen_markov)\n",
    "    \n",
    "    elif message.text == \"А болтать ты умеешь?\":\n",
    "        bot.send_message(message.chat.id, text=\"Просто начни диалог)\")\n",
    "        bot.register_next_step_handler(message, boltalka)\n",
    "        \n",
    "    else:\n",
    "        bot.send_message(message.chat.id, boltalka(message))      \n",
    "    \n",
    "def msimilar_one(message):\n",
    "    try: \n",
    "        text = most_similar_one(message.text)\n",
    "    except KeyError:\n",
    "        text = 'Прости, я таких слов не знаю. Попробуй что-то другое'\n",
    "    bot.send_message(message.chat.id, text)\n",
    "\n",
    "def msimilar_two(message):\n",
    "    try: \n",
    "        text = most_similar_two(message.text)\n",
    "    except KeyError:\n",
    "        text = 'Прости, я таких слов не знаю. Попробуй что-то другое'\n",
    "    bot.send_message(message.chat.id, text)\n",
    "\n",
    "def match_line(message):\n",
    "    try: \n",
    "        text = doesnt_match(message.text)\n",
    "    except KeyError:\n",
    "        text = 'Прости, я таких слов не знаю. Попробуй что-то другое'\n",
    "    bot.send_message(message.chat.id, text)\n",
    "\n",
    "def gen_markov(message):\n",
    "    try: \n",
    "        text = markov(message.text)\n",
    "    except KeyError:\n",
    "        text = 'Прости, я таких слов не знаю. Попробуй что-то другое'\n",
    "    bot.send_message(message.chat.id, text)\n",
    "\n",
    "def boltalka(message):\n",
    "    text = talk(message.text)\n",
    "    bot.send_message(message.chat.id, text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И запускаю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.polling(none_stop=True, interval=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоги"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот проект не был нацелен на создание идеального бота, который сгенерирует вам осмысленный текст, с помощью нейронок от TensorFlow, к примеру.\n",
    "\n",
    "Основная цель этого проекта - собрав тексты и обработав их, показать работу обученной модели, а так же представить генерацию текста цепями Маркова (и запихать это все в бота для удобства пользования). Здесь четко видно, где еще можно развиваться (к примеру, увеличить библиотеку... раз в 100, что поможет нам добиться большей \"осмысленности\"). Однако, свое творения я люблю даже таким немного глупеньким!\n",
    "\n",
    "Большое спасибо за внимание!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd6a621a747efe6ea34e577ba30c1478c757d991b11388f30676b42420b00154"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
